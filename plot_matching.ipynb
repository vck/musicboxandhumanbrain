{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div class=\"document\" id=\"robust-matching-using-ransac\">\n",
      "<h1 class=\"title\">Robust matching using RANSAC</h1>\n",
      "<p>In this simplified example we first generate two synthetic images as if they\n",
      "were taken from different view points.</p>\n",
      "<p>In the next step we find interest points in both images and find\n",
      "correspondences based on a weighted sum of squared differences of a small\n",
      "neighborhood around them. Note, that this measure is only robust towards\n",
      "linear radiometric and not geometric distortions and is thus only usable with\n",
      "slight view point changes.</p>\n",
      "<p>After finding the correspondences we end up having a set of source and\n",
      "destination coordinates which can be used to estimate the geometric\n",
      "transformation between both images. However, many of the correspondences are\n",
      "faulty and simply estimating the parameter set with all coordinates is not\n",
      "sufficient. Therefore, the RANSAC algorithm is used on top of the normal model\n",
      "to robustly estimate the parameter set by detecting outliers.</p>\n",
      "</div>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "\n",
      "from skimage import data\n",
      "from skimage.util import img_as_float\n",
      "from skimage.feature import (corner_harris, corner_subpix, corner_peaks,\n",
      "                             plot_matches)\n",
      "from skimage.transform import warp, AffineTransform\n",
      "from skimage.exposure import rescale_intensity\n",
      "from skimage.color import rgb2gray\n",
      "from skimage.measure import ransac\n",
      "\n",
      "\n",
      "# generate synthetic checkerboard image and add gradient for the later matching\n",
      "checkerboard = img_as_float(data.checkerboard())\n",
      "img_orig = np.zeros(list(checkerboard.shape) + [3])\n",
      "img_orig[..., 0] = checkerboard\n",
      "gradient_r, gradient_c = np.mgrid[0:img_orig.shape[0],\n",
      "                                  0:img_orig.shape[1]] / float(img_orig.shape[0])\n",
      "img_orig[..., 1] = gradient_r\n",
      "img_orig[..., 2] = gradient_c\n",
      "img_orig = rescale_intensity(img_orig)\n",
      "img_orig_gray = rgb2gray(img_orig)\n",
      "\n",
      "# warp synthetic image\n",
      "tform = AffineTransform(scale=(0.9, 0.9), rotation=0.2, translation=(20, -10))\n",
      "img_warped = warp(img_orig, tform.inverse, output_shape=(200, 200))\n",
      "img_warped_gray = rgb2gray(img_warped)\n",
      "\n",
      "# extract corners using Harris' corner measure\n",
      "coords_orig = corner_peaks(corner_harris(img_orig_gray), threshold_rel=0.001,\n",
      "                           min_distance=5)\n",
      "coords_warped = corner_peaks(corner_harris(img_warped_gray),\n",
      "                             threshold_rel=0.001, min_distance=5)\n",
      "\n",
      "# determine sub-pixel corner position\n",
      "coords_orig_subpix = corner_subpix(img_orig_gray, coords_orig, window_size=9)\n",
      "coords_warped_subpix = corner_subpix(img_warped_gray, coords_warped,\n",
      "                                     window_size=9)\n",
      "\n",
      "\n",
      "def gaussian_weights(window_ext, sigma=1):\n",
      "    y, x = np.mgrid[-window_ext:window_ext+1, -window_ext:window_ext+1]\n",
      "    g = np.zeros(y.shape, dtype=np.double)\n",
      "    g[:] = np.exp(-0.5 * (x**2 / sigma**2 + y**2 / sigma**2))\n",
      "    g /= 2 * np.pi * sigma * sigma\n",
      "    return g\n",
      "\n",
      "\n",
      "def match_corner(coord, window_ext=5):\n",
      "    r, c =  np.round(coord).astype(np.intp)\n",
      "    window_orig = img_orig[r-window_ext:r+window_ext+1,\n",
      "                           c-window_ext:c+window_ext+1, :]\n",
      "\n",
      "    # weight pixels depending on distance to center pixel\n",
      "    weights = gaussian_weights(window_ext, 3)\n",
      "    weights = np.dstack((weights, weights, weights))\n",
      "\n",
      "    # compute sum of squared differences to all corners in warped image\n",
      "    SSDs = []\n",
      "    for cr, cc in coords_warped:\n",
      "        window_warped = img_warped[cr-window_ext:cr+window_ext+1,\n",
      "                                   cc-window_ext:cc+window_ext+1, :]\n",
      "        SSD = np.sum(weights * (window_orig - window_warped)**2)\n",
      "        SSDs.append(SSD)\n",
      "\n",
      "    # use corner with minimum SSD as correspondence\n",
      "    min_idx = np.argmin(SSDs)\n",
      "    return coords_warped_subpix[min_idx]\n",
      "\n",
      "\n",
      "# find correspondences using simple weighted sum of squared differences\n",
      "src = []\n",
      "dst = []\n",
      "for coord in coords_orig_subpix:\n",
      "    src.append(coord)\n",
      "    dst.append(match_corner(coord))\n",
      "src = np.array(src)\n",
      "dst = np.array(dst)\n",
      "\n",
      "\n",
      "# estimate affine transform model using all coordinates\n",
      "model = AffineTransform()\n",
      "model.estimate(src, dst)\n",
      "\n",
      "# robustly estimate affine transform model with RANSAC\n",
      "model_robust, inliers = ransac((src, dst), AffineTransform, min_samples=3,\n",
      "                               residual_threshold=2, max_trials=100)\n",
      "outliers = inliers == False\n",
      "\n",
      "\n",
      "# compare \"true\" and estimated transform parameters\n",
      "print(tform.scale, tform.translation, tform.rotation)\n",
      "print(model.scale, model.translation, model.rotation)\n",
      "print(model_robust.scale, model_robust.translation, model_robust.rotation)\n",
      "\n",
      "# visualize correspondence\n",
      "fig, ax = plt.subplots(nrows=2, ncols=1)\n",
      "\n",
      "plt.gray()\n",
      "\n",
      "inlier_idxs = np.nonzero(inliers)[0]\n",
      "plot_matches(ax[0], img_orig_gray, img_warped_gray, src, dst,\n",
      "             np.column_stack((inlier_idxs, inlier_idxs)), matches_color='b')\n",
      "ax[0].axis('off')\n",
      "ax[0].set_title('Correct correspondences')\n",
      "\n",
      "outlier_idxs = np.nonzero(outliers)[0]\n",
      "plot_matches(ax[1], img_orig_gray, img_warped_gray, src, dst,\n",
      "             np.column_stack((outlier_idxs, outlier_idxs)), matches_color='r')\n",
      "ax[1].axis('off')\n",
      "ax[1].set_title('Faulty correspondences')\n",
      "\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.9, 0.9) [ 20. -10.] 0.2\n",
        "(0.9150655074453423, 0.8816374935151021) [-10.39162063  19.11736021] -0.194718117629\n",
        "(0.8999194500188994, 0.9000463268800499) [-10.00096544  19.97336708] -0.199907842544\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "\n",
      "from skimage import data\n",
      "from skimage.feature import corner_harris, corner_subpix, corner_peaks\n",
      "from skimage.transform import warp, AffineTransform\n",
      "from skimage.draw import ellipse\n",
      "\n",
      "\n",
      "tform = AffineTransform(scale=(1.3, 1.1), rotation=1, shear=0.7,\n",
      "                        translation=(210, 50))\n",
      "image = warp(data.checkerboard(), tform.inverse, output_shape=(350, 350))\n",
      "rr, cc = ellipse(310, 175, 10, 100)\n",
      "image[rr, cc] = 1\n",
      "image[180:230, 10:60] = 1\n",
      "image[230:280, 60:110] = 1\n",
      "\n",
      "coords = corner_peaks(corner_harris(image), min_distance=5)\n",
      "coords_subpix = corner_subpix(image, coords, window_size=13)\n",
      "\n",
      "fig, ax = plt.subplots()\n",
      "ax.imshow(image, interpolation='nearest', cmap=plt.cm.gray)\n",
      "ax.plot(coords[:, 1], coords[:, 0], '.b', markersize=3)\n",
      "ax.plot(coords_subpix[:, 1], coords_subpix[:, 0], '+r', markersize=15)\n",
      "ax.axis((0, 350, 350, 0))\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage import io, color, morphology\n",
      "from scipy.signal import convolve2d\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "img = color.rgb2gray(io.imread('samples/xsampel-a.jpg'))\n",
      "\n",
      "# Reduce all lines to one pixel thickness\n",
      "snakes = morphology.skeletonize(img < 1)\n",
      "\n",
      "# Find pixels with only one neighbor\n",
      "corners = convolve2d(snakes, [[1, 1, 1],\n",
      "                              [1, 0, 1],\n",
      "                              [1, 1, 1]], mode='same') == 1\n",
      "corners = corners & snakes\n",
      "\n",
      "# Those are the start and end positions of the segments\n",
      "y, x = np.where(corners)\n",
      "\n",
      "plt.imshow(img, cmap=plt.cm.gray, interpolation='nearest')\n",
      "plt.scatter(x, y)\n",
      "plt.axis('off')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Skeletonize requires a 2D array",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-7-3e84901b6560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'samples/xsampel-b.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Reduce all lines to one pixel thickness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msnakes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmorphology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskeletonize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Find pixels with only one neighbor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/morphology/_skeletonize.pyc\u001b[0m in \u001b[0;36mskeletonize\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m#  - binary image with only 0's and 1's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mskeleton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Skeletonize requires a 2D array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskeleton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Image contains values other than 0 and 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: Skeletonize requires a 2D array"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.feature import corner_harris,corner_peaks\n",
      "import skimage.io as io\n",
      "\n",
      "# More pyplot!\n",
      "def show_corners(corners,image,title=None):\n",
      "    \"\"\"Display a list of corners overlapping an image\"\"\"\n",
      "    fig = plt.figure()\n",
      "    plt.imshow(image)\n",
      "    # Convert coordinates to x and y lists\n",
      "    y_corner,x_corner = zip(*corners)\n",
      "    plt.plot(x_corner,y_corner,'o') # Plot corners\n",
      "    if title:\n",
      "        plt.title(title)\n",
      "    plt.xlim(0,image.shape[1])\n",
      "    plt.ylim(image.shape[0],0) # Images use weird axes\n",
      "    fig.set_size_inches(np.array(fig.get_size_inches()) * 1.5)\n",
      "    plt.show()\n",
      "\n",
      "image = io.imread('ub174.jpg', flatten=True)\n",
      "    \n",
      "corners = corner_peaks(corner_harris(image),min_distance=2)\n",
      "show_corners(corners,image,\n",
      "             title=\"Harris Corner Algorithm\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}